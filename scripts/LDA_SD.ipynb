{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas nltk gensim pyarrow fastparquet matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= POS-aware Cleaning Pipeline (NLTK) with lemma fixes =========\n",
    "import os, re, glob, json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# ---------- Ensure NLTK resources ----------\n",
    "for pkg in (\"stopwords\", \"punkt\", \"wordnet\"):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{pkg}\" if pkg != \"punkt\" else \"tokenizers/punkt\")\n",
    "    except LookupError:\n",
    "        nltk.download(pkg)\n",
    "\n",
    "# Tagger (try new name first, fallback to old one)\n",
    "try:\n",
    "    nltk.data.find(\"taggers/averaged_perceptron_tagger_eng\")\n",
    "except LookupError:\n",
    "    try:\n",
    "        nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "    except:\n",
    "        nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag_sents  # batch POS tagging for speed\n",
    "\n",
    "# ---------- Config ----------\n",
    "INPUT_ROOTS = [\n",
    "    os.path.join(\"..\", \"data\", \"raw\"),\n",
    "]\n",
    "OUTPUT_DIR  = os.path.join(\"..\", \"data\", \"final\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "GLOB_PATTERNS = {\n",
    "    \"Legend of Zelda\":        \"Legend*Wild*Comments*Analysis.parquet\",\n",
    "    \"Baldur's Gate 3\":        \"Baldur*Gate*3*Comments*Analysis.parquet\",\n",
    "    \"Elden Ring\":             \"Elden*Ring*Comments*Analysis.parquet\",\n",
    "    \"Hollow Knight\":          \"Hollow*Knight*Comments*Analysis.parquet\",\n",
    "    \"Red Dead Redemption 2\":  \"Red*Dead*Redemption*2*Comments*Analysis.parquet\",\n",
    "}\n",
    "\n",
    "# Phrase thresholds\n",
    "BIGRAM_MIN_COUNT = 5\n",
    "PHRASE_THRESHOLD = 8.0\n",
    "MIN_TOKENS_ROW   = 5\n",
    "\n",
    "# Dictionary pruning\n",
    "NO_BELOW = 5\n",
    "NO_ABOVE = 0.5\n",
    "KEEP_N   = 100_000\n",
    "\n",
    "# ---------- Stopwords ----------\n",
    "NLTK_STOP = set(stopwords.words(\"english\"))\n",
    "CUSTOM_STOP = {\n",
    "    'video','game','online','youtube','series','pls','lol','omg','xd','people','thing',\n",
    "    'play','make','time','love','look','want','think','watch','know','got','use','cant',\n",
    "    'going','never','ever','part','help','played','getting','doesnt','bad','pretty',\n",
    "    'show','fuck','talk','went','comment','cool','amazing','seen','best','like','get','one',\n",
    "    'dont','would','first','really','see','also','dan','way','guy','good','say','back',\n",
    "    'much','still','even','man','thats','need','bro','new','kid','every','always','could',\n",
    "    'said','please','youre','actually','didnt','feel','ive','dude','name',\n",
    "    'keep','gon','watching','everyone','hey','someone','made','come','great',\n",
    "    'give','well','fun','nice','let','right','day','friend','thought','work','mean','take',\n",
    "    'vid','lmao','lot','god','something','hope','put','cause','literally','since','next','hate',\n",
    "    'used','saying','funny','many','vids','episode','playthrough','playing','thank','thanks','sure',\n",
    "    'two','though','last','stuff','without','everything','maybe','second','around','long','place',\n",
    "    'point','already','year','little','another','better','fucking','shit','area','found','wait','merg',\n",
    "    'wouldnt','wouldve','youve','youll','wasnt','aint','couldnt','seems','happens','happened','taking',\n",
    "    'honestly','definitely','either','looking','looked','open','add','top','full','mine','kept','tried','gave','minute','damn',\n",
    "    'channel','walkthrough','content','using','done','start'\n",
    "}\n",
    "CREATOR_NAMES = {'arin','jack','brad','delirious','theradbrad','gamegrumps'}\n",
    "STOP_WORDS = NLTK_STOP.union(CUSTOM_STOP).union(CREATOR_NAMES)\n",
    "\n",
    "# ---------- Regex & helpers ----------\n",
    "URL_RE   = re.compile(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\")\n",
    "HTML_RE  = re.compile(r\"<.*?>\")\n",
    "PUNC_RE  = re.compile(r\"[^\\w\\s]\")\n",
    "DIGIT_RE = re.compile(r\"\\d+\")\n",
    "WS_RE    = re.compile(r\"\\s+\")\n",
    "\n",
    "LEMM = WordNetLemmatizer()\n",
    "\n",
    "# Fix lemmatization quirks (e.g., 'boss' -> 'bos')\n",
    "LEMMA_FIX = {\n",
    "    \"bos\": \"boss\",\n",
    "    # add more if spotted later\n",
    "}\n",
    "\n",
    "def _wn_pos(tag: str):\n",
    "    \"\"\"Map Penn POS to WordNet POS.\"\"\"\n",
    "    if not tag:\n",
    "        return wn.NOUN\n",
    "    t = tag[0]\n",
    "    if t == 'J': return wn.ADJ\n",
    "    if t == 'V': return wn.VERB\n",
    "    if t == 'N': return wn.NOUN\n",
    "    if t == 'R': return wn.ADV\n",
    "    return wn.NOUN\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = URL_RE.sub(\" \", text)\n",
    "    text = HTML_RE.sub(\" \", text)\n",
    "    text = PUNC_RE.sub(\" \", text)\n",
    "    text = DIGIT_RE.sub(\" \", text)\n",
    "    text = WS_RE.sub(\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize_simple(text: str):\n",
    "    return text.split()\n",
    "\n",
    "def pos_lemmatize_tokens(tokens):\n",
    "    tagged = list(pos_tag_sents([tokens]))[0]\n",
    "    return [LEMM.lemmatize(w, _wn_pos(tag)) for (w, tag) in tagged]\n",
    "\n",
    "def apply_lemma_fixes(tokens):\n",
    "    return [LEMMA_FIX.get(t, t) for t in tokens]\n",
    "\n",
    "def clean_text_pos(text: str):\n",
    "    \"\"\"Full cleaner with POS-aware lemmatization + lemma fixes.\"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return []\n",
    "    text = normalize(text)\n",
    "    toks = tokenize_simple(text)\n",
    "    toks = [t for t in toks if len(t) > 2]\n",
    "    if not toks:\n",
    "        return []\n",
    "    toks = pos_lemmatize_tokens(toks)        # POS-aware lemmatization\n",
    "    toks = apply_lemma_fixes(toks)           # fix known quirks (boss/bos)\n",
    "    toks = [t for t in toks if t not in STOP_WORDS and len(t) > 2]\n",
    "    return toks\n",
    "\n",
    "# ---------- Robust file resolver ----------\n",
    "def resolve_path(pattern, roots):\n",
    "    for root in roots:\n",
    "        matches = glob.glob(os.path.join(root, pattern))\n",
    "        if matches:\n",
    "            matches.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "# ---------- Load, clean, combine ----------\n",
    "cleaned_dfs, missing = [], []\n",
    "for game, pat in GLOB_PATTERNS.items():\n",
    "    fpath = resolve_path(pat, INPUT_ROOTS)\n",
    "    if not fpath:\n",
    "        print(f\"⚠️ No match for {game} with pattern {pat} in {INPUT_ROOTS}\")\n",
    "        missing.append(game)\n",
    "        continue\n",
    "    df = pd.read_parquet(fpath)\n",
    "    if not {'author','text'}.issubset(df.columns):\n",
    "        print(f\"⚠️ Required columns missing in {os.path.basename(fpath)} — skipping.\")\n",
    "        continue\n",
    "    df = df.dropna(subset=['author','text']).copy()\n",
    "    df['tokens'] = df['text'].map(clean_text_pos)\n",
    "    df = df[df['tokens'].str.len() > 0].drop_duplicates(subset=['text'])\n",
    "    df['game'] = game\n",
    "    cleaned_dfs.append(df)\n",
    "    print(f\"✅ {game}: {len(df)} rows — {os.path.basename(fpath)}\")\n",
    "\n",
    "if not cleaned_dfs:\n",
    "    raise SystemExit(\"No valid input files loaded.\")\n",
    "\n",
    "story_comments = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "print(\"📊 Per-game counts:\", story_comments['game'].value_counts().to_dict())\n",
    "\n",
    "# ---------- Phrase modeling (then refilter stopwords & reapply lemma fixes) ----------\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "bigram  = Phrases(story_comments['tokens'], min_count=BIGRAM_MIN_COUNT, threshold=PHRASE_THRESHOLD)\n",
    "trigram = Phrases(bigram[story_comments['tokens']], threshold=PHRASE_THRESHOLD)\n",
    "bigram_phraser  = Phraser(bigram)\n",
    "trigram_phraser = Phraser(trigram)\n",
    "\n",
    "def apply_phrases_and_refilter(toks):\n",
    "    phrased = trigram_phraser[bigram_phraser[toks]]\n",
    "    phrased = apply_lemma_fixes(phrased)  # catch any phrase-stage quirks\n",
    "    return [w for w in phrased if w not in STOP_WORDS and len(w) > 2]\n",
    "\n",
    "story_comments['tokens'] = story_comments['tokens'].apply(apply_phrases_and_refilter)\n",
    "\n",
    "# ---------- Row-level min-length filter ----------\n",
    "initial = len(story_comments)\n",
    "story_comments = story_comments[story_comments['tokens'].str.len() >= MIN_TOKENS_ROW]\n",
    "print(f\"✅ Removed {initial - len(story_comments)} short comments (<{MIN_TOKENS_ROW} tokens).\")\n",
    "\n",
    "# ---------- Token peek ----------\n",
    "all_tokens = [w for toks in story_comments['tokens'] for w in toks]\n",
    "print(\"🔹 Top 50 tokens:\", Counter(all_tokens).most_common(50))\n",
    "\n",
    "# ---------- Save cleaned ----------\n",
    "clean_path = os.path.join(OUTPUT_DIR, \"Filtered_Combined_SD_Cleaned.parquet\")\n",
    "story_comments.to_parquet(clean_path, index=False)\n",
    "print(f\"💾 Saved cleaned data -> {clean_path}\")\n",
    "\n",
    "# ---------- Dictionary / Corpus (with pruning knobs) ----------\n",
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary(story_comments['tokens'])\n",
    "dictionary.filter_extremes(no_below=NO_BELOW, no_above=NO_ABOVE, keep_n=KEEP_N)\n",
    "corpus = [dictionary.doc2bow(t) for t in story_comments['tokens']]\n",
    "print(f\"📚 Dictionary: {len(dictionary)} tokens | Corpus docs: {len(corpus)}\")\n",
    "\n",
    "dictionary.save(os.path.join(OUTPUT_DIR, \"lda_dictionary_SD.dict\"))\n",
    "\n",
    "# Save phrasers & corpus to avoid recompute later\n",
    "bigram_phraser.save(os.path.join(OUTPUT_DIR, \"bigram_SD.pkl\"))\n",
    "trigram_phraser.save(os.path.join(OUTPUT_DIR, \"trigram_SD.pkl\"))\n",
    "import pickle\n",
    "with open(os.path.join(OUTPUT_DIR, \"lda_corpus_SD.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(corpus, f)\n",
    "\n",
    "# Save basic metadata (handy for reproducibility)\n",
    "with open(os.path.join(OUTPUT_DIR, \"cleaning_meta_SD.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"no_below\": NO_BELOW,\n",
    "        \"no_above\": NO_ABOVE,\n",
    "        \"keep_n\": KEEP_N,\n",
    "        \"bigram_min_count\": BIGRAM_MIN_COUNT,\n",
    "        \"phrase_threshold\": PHRASE_THRESHOLD,\n",
    "        \"min_tokens_row\": MIN_TOKENS_ROW,\n",
    "        \"stopwords_sizes\": {\"nltk\": len(NLTK_STOP), \"custom\": len(CUSTOM_STOP), \"creators\": len(CREATOR_NAMES)},\n",
    "        \"lemma_fixes\": list(LEMMA_FIX.items()),\n",
    "    }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LDA K sweep (K = 1..35) — stratified split, CSV, and plots ===\n",
    "import os, math, json, random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# ---- Config ----\n",
    "INPUT_FILE      = os.path.join(\"..\", \"data\", \"final\", \"Filtered_Combined_SD_Cleaned.parquet\")\n",
    "OUT_DIR         = os.path.join(\"..\", \"data\", \"final\")\n",
    "DICT_PATH       = os.path.join(OUT_DIR, \"lda_dictionary_SD.dict\")  # use the name you saved\n",
    "K_GRID          = list(range(1, 36))  # 1..35 inclusive\n",
    "RANDOM_STATE    = 11\n",
    "PASSES, ITERS   = 5, 400              # can bump later when retraining best_k\n",
    "CHUNKSIZE       = 2000\n",
    "WORKERS         = os.cpu_count()\n",
    "\n",
    "RESULTS_CSV     = os.path.join(OUT_DIR, \"lda_k_selection_SD_metrics_1_35.csv\")\n",
    "SPLIT_JSON      = os.path.join(OUT_DIR, \"lda_split_SD_stratified.json\")\n",
    "PLOT_COMBINED   = os.path.join(OUT_DIR, \"lda_k_sweep_SD_1_35.png\")\n",
    "PLOT_COH_ONLY   = os.path.join(OUT_DIR, \"lda_k_sweep_SD_coherence_only.png\")\n",
    "PLOT_LP_ONLY    = os.path.join(OUT_DIR, \"lda_k_sweep_SD_logperp_only.png\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Load ----\n",
    "print(\"📂 Loading data/dictionary...\")\n",
    "df = pd.read_parquet(INPUT_FILE)\n",
    "texts = df[\"tokens\"].tolist()\n",
    "games = df[\"game\"].tolist() if \"game\" in df.columns else [\"ALL\"] * len(texts)\n",
    "\n",
    "dictionary = Dictionary.load(DICT_PATH)\n",
    "corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "print(f\"✅ docs={len(corpus)}  vocab={len(dictionary)}\")\n",
    "\n",
    "# ---- Stratified train/test split by game (90/10) ----\n",
    "rng = random.Random(RANDOM_STATE)\n",
    "by_game = defaultdict(list)\n",
    "for i, g in enumerate(games):\n",
    "    by_game[g].append(i)\n",
    "\n",
    "hold_idx = set()\n",
    "for g, idxs in by_game.items():\n",
    "    rng.shuffle(idxs)\n",
    "    k = max(1, int(0.10 * len(idxs)))  # 10% per game\n",
    "    hold_idx.update(idxs[:k])\n",
    "\n",
    "train_idx = [i for i in range(len(corpus)) if i not in hold_idx]\n",
    "test_idx  = [i for i in range(len(corpus)) if i in hold_idx]\n",
    "\n",
    "train_corpus = [corpus[i] for i in train_idx]\n",
    "test_corpus  = [corpus[i] for i in test_idx]\n",
    "train_texts  = [texts[i] for i in train_idx]\n",
    "\n",
    "with open(SPLIT_JSON, \"w\") as f:\n",
    "    json.dump({\"random_state\": RANDOM_STATE, \"train_idx\": train_idx, \"test_idx\": test_idx}, f)\n",
    "print(f\"🧪 Stratified split — Train: {len(train_corpus)}  Test: {len(test_corpus)}\")\n",
    "\n",
    "# ---- Train/eval helper ----\n",
    "def train_eval(k: int):\n",
    "    model = LdaMulticore(\n",
    "        corpus=train_corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=k,\n",
    "        passes=PASSES,\n",
    "        iterations=ITERS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        workers=WORKERS,\n",
    "        chunksize=CHUNKSIZE,\n",
    "        eval_every=None,\n",
    "        # Optional priors to try later:\n",
    "        # alpha='asymmetric', eta=None\n",
    "    )\n",
    "    # Coherence on TRAIN to avoid leakage\n",
    "    c_v = CoherenceModel(model=model, texts=train_texts, dictionary=dictionary, coherence=\"c_v\").get_coherence()\n",
    "    # Held-out log_perplexity: higher (less negative) is better\n",
    "    log_perp = model.log_perplexity(test_corpus)\n",
    "    return model, c_v, log_perp\n",
    "\n",
    "# ---- Sweep K ----\n",
    "rows = []\n",
    "best = {\"k\": None, \"c_v\": -math.inf, \"log_perplexity\": -math.inf, \"model\": None}\n",
    "\n",
    "for k in K_GRID:\n",
    "    print(f\"\\n⏳ Training LDA (k={k}) ...\")\n",
    "    model, c_v, log_perp = train_eval(k)\n",
    "    print(f\"📈 k={k} | c_v={c_v:.4f} | log_perplexity={log_perp:.4f} (higher = better)\")\n",
    "    rows.append({\"k\": k, \"c_v\": c_v, \"log_perplexity\": log_perp})\n",
    "\n",
    "    # Best by highest c_v; tie-break by highest log_perplexity\n",
    "    if (c_v > best[\"c_v\"]) or (math.isclose(c_v, best[\"c_v\"], rel_tol=1e-6) and log_perp > best[\"log_perplexity\"]):\n",
    "        best.update({\"k\": k, \"c_v\": c_v, \"log_perplexity\": log_perp, \"model\": model})\n",
    "\n",
    "# ---- Save metrics table ----\n",
    "dfm = pd.DataFrame(rows).sort_values(\"k\")\n",
    "dfm.to_csv(RESULTS_CSV, index=False)\n",
    "print(f\"\\n📝 Saved metrics -> {RESULTS_CSV}\")\n",
    "\n",
    "# ---- Save best model & topic terms ----\n",
    "best_k = best[\"k\"]\n",
    "best_model = best[\"model\"]\n",
    "best_path = os.path.join(OUT_DIR, f\"best_lda_model_SD_k{best_k}.model\")\n",
    "best_model.save(best_path)\n",
    "print(f\"🏆 Best K={best_k} | c_v={best['c_v']:.4f} | log_perplexity={best['log_perplexity']:.4f}\")\n",
    "print(f\"💾 Saved best model -> {best_path}\")\n",
    "\n",
    "def dump_topics(model, topn=20, path=None):\n",
    "    rows = []\n",
    "    for t in range(model.num_topics):\n",
    "        for rank, (w, p) in enumerate(model.show_topic(t, topn=topn), start=1):\n",
    "            rows.append({\"topic\": t, \"rank\": rank, \"word\": w, \"prob\": p})\n",
    "    dt = pd.DataFrame(rows)\n",
    "    if path: dt.to_csv(path, index=False)\n",
    "    return dt\n",
    "\n",
    "topics_csv = os.path.join(OUT_DIR, f\"best_topics_SD_k{best_k}.csv\")\n",
    "dump_topics(best_model, topn=20, path=topics_csv)\n",
    "print(f\"🗂️ Topic top-terms saved -> {topics_csv}\")\n",
    "\n",
    "# ---- Plots ----\n",
    "def plot_combined(df, best_k, out_path):\n",
    "    df = df.sort_values(\"k\")\n",
    "    fig, ax1 = plt.subplots(figsize=(9, 5))\n",
    "    ax1.plot(df[\"k\"], df[\"c_v\"], marker=\"o\", label=\"c_v\")\n",
    "    ax1.set_xlabel(\"K (number of topics)\")\n",
    "    ax1.set_ylabel(\"Coherence (c_v)\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df[\"k\"], df[\"log_perplexity\"], marker=\"s\", linestyle=\"--\", label=\"log_perplexity\")\n",
    "    ax2.set_ylabel(\"log_perplexity (higher is better)\")\n",
    "\n",
    "    ax1.axvline(best_k, linestyle=\":\", linewidth=1.5)\n",
    "    ax1.set_title(f\"LDA K Sweep (K=1..35) — Best K={best_k}\")\n",
    "\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"🖼️ Saved combined plot -> {out_path}\")\n",
    "\n",
    "def plot_single(x, y, ylabel, title, out_path, marker=\"o\"):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x, y, marker=marker)\n",
    "    plt.xlabel(\"K (number of topics)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"🖼️ Saved plot -> {out_path}\")\n",
    "\n",
    "# Combined (twin-axis)\n",
    "plot_combined(dfm, best_k, PLOT_COMBINED)\n",
    "\n",
    "# Separate per-metric plots\n",
    "plot_single(dfm[\"k\"], dfm[\"c_v\"], \"Coherence (c_v)\", \"LDA K Sweep — Coherence\", PLOT_COH_ONLY, marker=\"o\")\n",
    "plot_single(dfm[\"k\"], dfm[\"log_perplexity\"], \"log_perplexity (higher is better)\", \"LDA K Sweep — log_perplexity\", PLOT_LP_ONLY, marker=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LDA K micro-sweep (K = 2..6) — reuse stratified split, CSV, and plots ===\n",
    "import os, math, json, random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# ---- Config ----\n",
    "OUT_DIR   = os.path.join(\"..\", \"data\", \"final\")\n",
    "INPUT     = os.path.join(OUT_DIR, \"Filtered_Combined_SD_Cleaned.parquet\")\n",
    "DICT_PATH = os.path.join(OUT_DIR, \"lda_dictionary_SD.dict\")\n",
    "\n",
    "K_GRID = list(range(2, 7))  # 2..6 inclusive\n",
    "RANDOM_STATE = 11\n",
    "PASSES, ITERS = 5, 400       # can bump after picking K\n",
    "CHUNKSIZE = 2000\n",
    "WORKERS = os.cpu_count()\n",
    "\n",
    "RESULTS_CSV   = os.path.join(OUT_DIR, \"lda_k_selection_SD_metrics_2_6.csv\")\n",
    "SPLIT_JSON    = os.path.join(OUT_DIR, \"lda_split_SD_stratified.json\")\n",
    "PLOT_COMBINED = os.path.join(OUT_DIR, \"lda_k_sweep_SD_2_6.png\")\n",
    "PLOT_COH_ONLY = os.path.join(OUT_DIR, \"lda_k_sweep_SD_2_6_coherence.png\")\n",
    "PLOT_LP_ONLY  = os.path.join(OUT_DIR, \"lda_k_sweep_SD_2_6_logperp.png\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---- Load data/dictionary ----\n",
    "print(\"📂 Loading data/dictionary...\")\n",
    "df = pd.read_parquet(INPUT)\n",
    "texts = df[\"tokens\"].tolist()\n",
    "games = df[\"game\"].tolist() if \"game\" in df.columns else [\"ALL\"] * len(texts)\n",
    "dictionary = Dictionary.load(DICT_PATH)\n",
    "corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "print(f\"✅ docs={len(corpus)}  vocab={len(dictionary)}\")\n",
    "\n",
    "# ---- Load or create stratified split (90/10 by game) ----\n",
    "if os.path.exists(SPLIT_JSON):\n",
    "    print(f\"🔁 Using existing split: {SPLIT_JSON}\")\n",
    "    with open(SPLIT_JSON, \"r\") as f:\n",
    "        split = json.load(f)\n",
    "    train_idx, test_idx = split[\"train_idx\"], split[\"test_idx\"]\n",
    "else:\n",
    "    print(\"🆕 Creating stratified split (90/10 by game)...\")\n",
    "    rng = random.Random(RANDOM_STATE)\n",
    "    by_game = defaultdict(list)\n",
    "    for i, g in enumerate(games): by_game[g].append(i)\n",
    "\n",
    "    hold_idx = set()\n",
    "    for g, idxs in by_game.items():\n",
    "        rng.shuffle(idxs)\n",
    "        k = max(1, int(0.10 * len(idxs)))\n",
    "        hold_idx.update(idxs[:k])\n",
    "\n",
    "    train_idx = [i for i in range(len(corpus)) if i not in hold_idx]\n",
    "    test_idx  = [i for i in range(len(corpus)) if i in hold_idx]\n",
    "    with open(SPLIT_JSON, \"w\") as f:\n",
    "        json.dump({\"random_state\": RANDOM_STATE, \"train_idx\": train_idx, \"test_idx\": test_idx}, f)\n",
    "\n",
    "train_corpus = [corpus[i] for i in train_idx]\n",
    "test_corpus  = [corpus[i] for i in test_idx]\n",
    "train_texts  = [texts[i] for i in train_idx]\n",
    "print(f\"🧪 Train: {len(train_corpus)}  Test: {len(test_corpus)}\")\n",
    "\n",
    "# ---- Train/eval helper ----\n",
    "def train_eval(k: int):\n",
    "    model = LdaMulticore(\n",
    "        corpus=train_corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=k,\n",
    "        passes=PASSES,\n",
    "        iterations=ITERS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        workers=WORKERS,\n",
    "        chunksize=CHUNKSIZE,\n",
    "        eval_every=None,\n",
    "        # alpha='asymmetric', eta=None  # optional to try later\n",
    "    )\n",
    "    c_v = CoherenceModel(model=model, texts=train_texts, dictionary=dictionary, coherence=\"c_v\").get_coherence()\n",
    "    log_perp = model.log_perplexity(test_corpus)  # higher (less negative) is better\n",
    "    return model, c_v, log_perp\n",
    "\n",
    "# ---- Sweep ----\n",
    "rows = []\n",
    "best = {\"k\": None, \"c_v\": -math.inf, \"log_perplexity\": -math.inf, \"model\": None}\n",
    "\n",
    "for k in K_GRID:\n",
    "    print(f\"\\n⏳ Training LDA (k={k}) ...\")\n",
    "    model, c_v, log_perp = train_eval(k)\n",
    "    print(f\"📈 k={k} | c_v={c_v:.4f} | log_perplexity={log_perp:.4f} (higher = better)\")\n",
    "    rows.append({\"k\": k, \"c_v\": c_v, \"log_perplexity\": log_perp})\n",
    "    if (c_v > best[\"c_v\"]) or (math.isclose(c_v, best[\"c_v\"], rel_tol=1e-6) and log_perp > best[\"log_perplexity\"]):\n",
    "        best.update({\"k\": k, \"c_v\": c_v, \"log_perplexity\": log_perp, \"model\": model})\n",
    "\n",
    "# ---- Save metrics ----\n",
    "dfm = pd.DataFrame(rows).sort_values(\"k\")\n",
    "dfm.to_csv(RESULTS_CSV, index=False)\n",
    "print(f\"\\n📝 Saved metrics -> {RESULTS_CSV}\")\n",
    "print(f\"🏆 Best K={best['k']} | c_v={best['c_v']:.4f} | log_perplexity={best['log_perplexity']:.4f}\")\n",
    "\n",
    "# ---- Plots ----\n",
    "def plot_combined(df, best_k, out_path):\n",
    "    df = df.sort_values(\"k\")\n",
    "    fig, ax1 = plt.subplots(figsize=(9, 5))\n",
    "    ax1.plot(df[\"k\"], df[\"c_v\"], marker=\"o\", label=\"c_v\")\n",
    "    ax1.set_xlabel(\"K (number of topics)\")\n",
    "    ax1.set_ylabel(\"Coherence (c_v)\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df[\"k\"], df[\"log_perplexity\"], marker=\"s\", linestyle=\"--\", label=\"log_perplexity\")\n",
    "    ax2.set_ylabel(\"log_perplexity (higher is better)\")\n",
    "\n",
    "    ax1.axvline(best_k, linestyle=\":\", linewidth=1.5)\n",
    "    ax1.set_title(f\"LDA K Sweep (K=2..6) — Best K={best_k}\")\n",
    "\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"🖼️ Saved combined plot -> {out_path}\")\n",
    "\n",
    "def plot_single(x, y, ylabel, title, out_path, marker=\"o\"):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x, y, marker=marker)\n",
    "    plt.xlabel(\"K (number of topics)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"🖼️ Saved plot -> {out_path}\")\n",
    "\n",
    "plot_combined(dfm, best[\"k\"], PLOT_COMBINED)\n",
    "plot_single(dfm[\"k\"], dfm[\"c_v\"], \"Coherence (c_v)\", \"LDA K Sweep — Coherence (2..6)\", PLOT_COH_ONLY, marker=\"o\")\n",
    "plot_single(dfm[\"k\"], dfm[\"log_perplexity\"], \"log_perplexity (higher is better)\", \"LDA K Sweep — log_perplexity (2..6)\", PLOT_LP_ONLY, marker=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Finalize: Train the final K=3 model on the FULL corpus and export artifacts ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "OUT_DIR   = os.path.join(\"..\", \"data\", \"final\")\n",
    "INPUT     = os.path.join(OUT_DIR, \"Filtered_Combined_SD_Cleaned.parquet\")\n",
    "DICT_PATH = os.path.join(OUT_DIR, \"lda_dictionary_SD.dict\")\n",
    "\n",
    "BEST_K    = 3\n",
    "RND       = 11\n",
    "PASSES    = 20\n",
    "ITERS     = 1000\n",
    "CHUNKSIZE = 2000\n",
    "WORKERS   = os.cpu_count()\n",
    "\n",
    "print(\"📂 Loading full corpus/dictionary...\")\n",
    "df = pd.read_parquet(INPUT)\n",
    "texts = df[\"tokens\"].tolist()\n",
    "games = df[\"game\"].tolist() if \"game\" in df.columns else [\"ALL\"] * len(texts)\n",
    "dictionary = Dictionary.load(DICT_PATH)\n",
    "corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "print(f\"✅ docs={len(corpus)}  vocab={len(dictionary)}\")\n",
    "\n",
    "print(f\"⏳ Training FINAL model on ALL docs (K={BEST_K}) ...\")\n",
    "final_model = LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=BEST_K,\n",
    "    passes=PASSES,\n",
    "    iterations=ITERS,\n",
    "    random_state=RND,\n",
    "    workers=WORKERS,\n",
    "    chunksize=CHUNKSIZE,\n",
    "    eval_every=None,\n",
    "    alpha='asymmetric',\n",
    "    eta='auto'\n",
    ")\n",
    "\n",
    "# ---- Save model ----\n",
    "final_model_path = os.path.join(OUT_DIR, f\"final_lda_SD_k{BEST_K}.model\")\n",
    "final_model.save(final_model_path)\n",
    "print(f\"💾 Saved final model -> {final_model_path}\")\n",
    "\n",
    "# ---- Export: topic top terms ----\n",
    "rows = []\n",
    "for t in range(BEST_K):\n",
    "    for rank, (w, p) in enumerate(final_model.show_topic(t, topn=25), start=1):\n",
    "        rows.append({\"topic\": t, \"rank\": rank, \"word\": w, \"prob\": p})\n",
    "topics_csv = os.path.join(OUT_DIR, f\"final_topics_SD_k{BEST_K}.csv\")\n",
    "pd.DataFrame(rows).to_csv(topics_csv, index=False)\n",
    "print(f\"🗂️ Topic words saved -> {topics_csv}\")\n",
    "\n",
    "# ---- Export: per-game topic prevalence ----\n",
    "# Assign each doc to its most probable topic\n",
    "doc_top = final_model.get_document_topics\n",
    "topic_game_counts = defaultdict(lambda: Counter())\n",
    "for i, bow in enumerate(corpus):\n",
    "    dt = doc_top(bow)\n",
    "    if not dt:\n",
    "        continue\n",
    "    top_topic, top_prob = max(dt, key=lambda x: x[1])\n",
    "    topic_game_counts[top_topic][games[i]] += 1\n",
    "\n",
    "pg_rows = []\n",
    "for t in range(BEST_K):\n",
    "    total = sum(topic_game_counts[t].values())\n",
    "    for g, c in topic_game_counts[t].items():\n",
    "        pg_rows.append({\n",
    "            \"topic\": t,\n",
    "            \"game\": g,\n",
    "            \"count\": c,\n",
    "            \"share_in_topic\": (c / total) if total else 0.0\n",
    "        })\n",
    "per_game_csv = os.path.join(OUT_DIR, f\"final_topic_by_game_SD_k{BEST_K}.csv\")\n",
    "pd.DataFrame(pg_rows).to_csv(per_game_csv, index=False)\n",
    "print(f\"📊 Per-game prevalence saved -> {per_game_csv}\")\n",
    "\n",
    "# ---- Export: per-doc dominant topic (optional but handy) ----\n",
    "doc_rows = []\n",
    "for i, bow in enumerate(corpus):\n",
    "    dt = doc_top(bow)\n",
    "    if dt:\n",
    "        t, p = max(dt, key=lambda x: x[1])\n",
    "    else:\n",
    "        t, p = -1, 0.0\n",
    "    doc_rows.append({\n",
    "        \"doc_id\": i,\n",
    "        \"game\": games[i],\n",
    "        \"dominant_topic\": t,\n",
    "        \"dominant_prob\": p\n",
    "    })\n",
    "per_doc_csv = os.path.join(OUT_DIR, f\"final_doc_topics_SD_k{BEST_K}.csv\")\n",
    "pd.DataFrame(doc_rows).to_csv(per_doc_csv, index=False)\n",
    "print(f\"🧾 Per-doc dominant topics saved -> {per_doc_csv}\")\n",
    "\n",
    "print(\"✅ Finalization complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
